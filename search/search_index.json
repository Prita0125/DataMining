{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TUGAS PENAMBANGAN DATA Nama : PRITA DYAH ANINDHITA NPM : 180411100125 TUGAS 1 : Menganalisa Data Statistika Penambangan data adalah bagaimana mendapatkan informasi yang berharga untuk pijakan pengambilan keputusan atau tujuan tertentu. Dalama proses data mining melibatkan teknik statistik, matematika, kecerdasan buatan, machine learning untuk mengekstraksi dan mengidentifikasi informasi yang bermanfaat dan pengetahuan yang terkait dari berbagai database besar. Proses yang umumnya dilakukan oleh data mining antara lain: deskripsi, prediksi, estimasi, klasifikasi, clustering dan asosiasi. Secara rinci proses data mining dijelaskan sebagai berikut (Larose, 2005): a. Deskripsi Deskripsi bertujuan untuk mengidentifikasi pola yang muncul secara berulang pada suatu data dan mengubah pola tersebut menjadi aturan dan kriteria yang dapat mudah dimengerti oleh para ahli pada domain aplikasinya. Aturan yang dihasilkan harus mudah dimengerti agar dapat dengan efektif meningkatkan tingkat pengetahuan (knowledge) pada sistem. Tugas deskriptif merupakan tugas data mining yang sering dibutuhkan pada teknik postprocessing untuk melakukan validasi dan menjelaskan hasil dari proses data mining. Postprocessing merupakan proses yang digunakan untuk memastikan hanya hasil yang valid dan berguna yang dapat digunakan oleh pihak yang berkepentingan. b. Prediksi Prediksi memiliki kemiripan dengan klasifikasi, akan tetapi data diklasifikasikan berdasarkan perilaku atau nilai yang diperkirakan pada masa yang akan datang. Contoh dari tugas prediksi misalnya untuk memprediksikan adanya pengurangan jumlah pelanggan dalam waktu dekat dan prediksi harga saham dalam tiga bulan yang akan datang. c. Estimasi Estimasi hampir sama dengan prediksi, kecuali variabel target estimasi lebih ke arah numerik dari pada ke arah kategori. Model dibangun menggunakan record lengkap yang menyediakan nilai dari variabel target sebagai nilai prediksi. Selanjutnya, pada peninjauan berikutnya estimasi nilai dari variabel target dibuat berdasarkan nilai variabel prediksi. Sebagai contoh, akan dilakukan estimasi tekanan darah sistolik pada pasien rumah sakit berdasarkan umur pasien, jenis kelamin, berat badan, dan level sodium darah. Hubungan antara tekanan darah sistolik dan nilai variabel prediksi dalam proses pembelajaran akan menghasilkan model estimasi. d. Klasifikasi Klasifikasi merupakan proses menemukan sebuah model atau fungsi yang mendeskripsikan dan membedakan data ke dalam kelas-kelas. Klasifikasi melibatkan proses pemeriksaan karakteristik dari objek dan memasukkan objek ke dalam salah satu kelas yang sudah didefinisikan sebelumnya. e. Clustering Clustering merupakan pengelompokan data tanpa berdasarkan kelas data tertentu ke dalam kelas objek yang sama. Sebuah kluster adalah kumpulan record yang memiliki kemiripan suatu dengan yang lainnya dan memiliki ketidakmiripan dengan record dalam kluster lain. Tujuannya adalah untuk menghasilkan pengelompokan objek yang mirip satu sama lain dalam kelompok-kelompok. Semakin besar kemiripan objek dalam suatu cluster dan semakin besar perbedaan tiap cluster maka kualitas analisis cluster semakin baik. f. Asosiasi Tugas asosiasi dalam data mining adalah menemukan atribut yang muncul dalam suatu waktu. Dalam dunia bisnis lebih umum disebut analisis keranjang belanja (market basket analisys). Tugas asosiasi berusaha untuk mengungkap aturan untuk mengukur hubungan antara dua atau lebih atribut. Data Penjualan Celana Jeans ukuran harga terjual stok_akhir 27 199646 80 125 28 217629 68 120 33 194895 73 126 27 243520 59 114 33 189647 76 91 28 231199 57 99 28 201023 58 119 32 237461 73 94 28 181524 51 101 27 209713 78 107 31 196850 61 101 29 235810 57 92 30 210073 70 99 28 230566 79 127 27 191428 54 104 33 196716 69 127 33 180778 80 121 27 241827 66 114 30 235338 80 124 27 246301 64 98 28 242698 51 110 30 227316 80 91 28 213416 63 93 32 248338 54 127 32 189835 60 98 27 229830 65 124 29 228902 54 100 32 188186 70 108 29 214059 78 97 30 212963 50 127 31 178144 70 101 32 181112 67 124 27 221751 71 93 29 242167 77 108 27 197905 54 116 30 197365 51 116 30 215260 77 92 30 234018 71 90 31 217349 55 93 28 236345 79 98 29 200676 50 112 29 243220 80 107 31 240486 64 93 29 228497 62 112 31 201558 75 122 28 187013 76 101 32 238585 79 121 29 248879 53 119 31 220055 52 110 28 179157 74 119 32 218099 61 118 33 202469 73 108 28 196962 63 108 30 204666 76 109 31 220382 67 123 30 243236 65 116 32 231079 80 101 30 224545 80 102 32 204638 50 100 28 204997 56 98 33 175450 59 109 31 208584 71 107 29 181341 50 115 27 177602 76 96 29 244126 51 124 27 175884 69 106 29 194168 70 125 29 209596 70 90 31 216842 70 98 32 232769 78 125 33 242237 80 124 29 221570 53 90 32 234874 63 96 27 240559 50 95 28 186485 71 114 33 186471 60 128 28 204356 69 111 33 202393 59 92 27 194641 65 113 32 249103 78 127 29 221927 66 105 27 231445 70 103 28 244795 66 120 33 224554 70 114 31 186151 51 96 32 199054 55 111 28 237222 51 114 30 176109 76 100 33 208126 77 96 29 213399 62 108 28 193254 78 124 33 247786 52 114 32 233411 76 126 27 199631 79 106 29 234684 62 110 32 245464 62 110 33 232024 71 108 29 200812 64 90 30 198037 78 103 32 221239 52 90 Pengolahan Data import pandas as pd df = pd.read_csv( data_penjualan1.csv ) df from IPython.display import HTML, display import tabulate table=[ [ method ]+[x for x in df.columns], [ describe() ]+[' pre '+str(df[col].describe())+' /pre ' for col in df.columns], [ count() ]+[df[col].count() for col in df.columns], [ mean() ]+[df[col].mean() for col in df.columns], [ std() ]+[ {:.2f} .format(df[col].std()) for col in df.columns], [ min() ]+[df[col].min() for col in df.columns], [ max() ]+[df[col].max() for col in df.columns], [ q1() ]+[df[col].quantile(0.25) for col in df.columns], [ q2() ]+[df[col].quantile(0.50) for col in df.columns], [ q3() ]+[df[col].quantile(0.75) for col in df.columns], [ skew() ]+[ {:.2f} .format(df[col].skew()) for col in df.columns], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Hasil pengolahan data : method ukuran harga terjual stok_akhir describe() count 100.000000 count 100.000000 count 100.000000 count 100.000000 mean 29.850000 mean 214562.770000 mean 66.160000 mean 108.410000 std 2.031942 std 21792.270555 std 9.909408 std 11.655055 min 27.000000 min 175450.000000 min 50.000000 min 90.000000 25% 28.000000 25% 197264.250000 25% 57.750000 25% 98.000000 50% 30.000000 50% 214659.500000 50% 67.000000 50% 108.000000 75% 32.000000 75% 234184.500000 75% 76.000000 75% 119.000000 max 33.000000 max 249103.000000 max 80.000000 max 128.000000 Name: ukuran, dtype: float64 Name: harga, dtype: float64 Name: terjual, dtype: float64 Name: stok_akhir, dtype: float64 count() 100 100 100 100 mean() 29.85 214562.77 66.16 108.41 std() 2.03 21792.27 9.91 11.66 min() 27 175450 50 90 max() 33 249103 80 128 q1() 28 197264.25 57.75 98 q2() 30 214659.5 67 108 q3() 32 234184.5 76 119 skew() 0.14 -0.1 -0.19 0.07 TUGAS 2 : Mengukur Jarak Data Dalam data, terdapat macam-macam atribut. Atribut adalah data yang mewakili karakteristik atau fitur dari objek data. Atribut bisa disebut juga dengan dimensi, fitur, dan variabel yang istilah itu sering digunakan literatur. Dalam penambangan data atau data miniing dan database biasa menggunakan istilah atribut atau fitur , dan dalam buku ini juga menggunakan istilah atribut atau fitur. Jenis atribut ditentukan oleh nilai-nilai pada atribut tersebut yang mungkin nominal, biner,atau ordinal, atau numerik. Mengukur Jarak Data Tipe Numerik : Minkowski Distance Manhattan Distance Euclidean Distance Average Distance Weighted Euclidean Distance Chord Distance Mahalanobis Distance Cosine Measure Pearson Measure Tipe Binary Tipe Categorical: Overlay metric Value Difference Metric Minimum Risk Metric Tipe Ordinal DATA BUPA LIVER DISORDER Title : BUPA liver disorders Source information : Creators : BUPA Medical Research Ltd. Donor : Richard S. Forsyth Address : 8 Grosvenor Avenue Mapperley Park Nottingham NG3 5DX 0602-621676 Date : 5/15/1990 import pandas as pd df = pd.read_csv( bupa_liver_disorder.csv ,nrows=4) df mcv alkphos spgt sgot gammagt drinks selector 0 85 92 45 27 31 0 1 1 85 64 59 32 23 0 2 2 86 54 33 16 54 0 2 3 91 78 34 24 36 0 2 binary=[6] num=[0,1,2,3,4,5] from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[0]+[0], [ v1-v3 ]+[0]+[0]+[0], [ v2-v3 ]+[0]+[0]+[0], [ v3-v4 ]+[0]+[0]+[0], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 0 0 v1-v3 0 0 0 v2-v3 0 0 0 v3-v4 0 0 0 def chordDist(v1,v2,jnis): jmlh=0 normv1=0 normv2=0 for x in range (len(jnis)): normv1=normv1+(int(df.values.tolist()[v1][jnis[x]])**2) normv2=normv2+(int(df.values.tolist()[v2][jnis[x]])**2) jmlh=jmlh+(int(df.values.tolist()[v1][jnis[x]])*int(df.values.tolist()[v2][jnis[x]])) return ((2-(2*jmlh/(normv1*normv2)))**0.5) from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[chordDist(0,1,num)]+[0], [ v1-v3 ]+[0]+[chordDist(0,2,num)]+[0], [ v2-v3 ]+[0]+[chordDist(1,2,num)]+[0], [ v3-v4 ]+[0]+[chordDist(2,3,num)]+[0], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 1.41421356237 0 v1-v3 0 1.41421356237 0 v2-v3 0 1.41421356237 0 v3-v4 0 1.41421356237 0 BINARY def binaryDist(v1,v2,jnis): q=0 r=0 s=0 t=0 for x in range (len(jnis)): if (int(df.values.tolist()[v1][jnis[x]]))==1 and (int(df.values.tolist()[v2][jnis[x]]))==1: q=q+1 elif (int(df.values.tolist()[v1][jnis[x]]))==1 and (int(df.values.tolist()[v2][jnis[x]]))==2: r=r+1 elif (int(df.values.tolist()[v1][jnis[x]]))==2 and (int(df.values.tolist()[v2][jnis[x]]))==1: s=s+1 else: t=t+1 return ((r+s)/(q+r+s+t)) from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[chordDist(0,1,num)]+[binaryDist(0,1,binary)], [ v1-v3 ]+[0]+[chordDist(0,2,num)]+[binaryDist(0,2,binary)], [ v2-v3 ]+[0]+[chordDist(1,2,num)]+[binaryDist(1,2,binary)], [ v3-v4 ]+[0]+[chordDist(2,3,num)]+[binaryDist(2,3,binary)], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 1.41421356237 1 v1-v3 0 1.41421356237 1 v2-v3 0 1.41421356237 0 v3-v4 0 1.41421356237 0 TUGAS 3 : SELEKSI FITUR INFORMATION GAIN Seleksi fitur merupakan salah satu fokus penelitian pada data mining untuk dataset yang memiliki atribut yang relatif banyak. Dengan menghilangkan beberapa atribut yang tidak relevan terhadap kelas label akan dapat meningkatkan kinerja algoritma klasifikasi. INFORMATION GAIN Information Gain adalah metode yang menggunakan teknik scoring untuk pembobotan sebuah fitur dengan menggunakan maksimal entropy from pandas import * from IPython.display import HTML, display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table(df): display(HTML(tabulate(df, tablefmt='html', headers='keys', showindex=False))) df = read_csv('newdata.csv', sep=';') table(df) outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no Mencari Entropy Target def findEntropy(column): rawGroups = df.groupby(column) targetGroups = [[key, len(data), len(data)/df[column].size] for key,data in rawGroups] targetGroups = DataFrame(targetGroups, columns=['value', 'count', 'probability']) return sum([-x*log(x,2) for x in targetGroups['probability']]), targetGroups, rawGroups entropyTarget, groupTargets, _ = findEntropy('play') table(groupTargets) print('entropy target =', entropyTarget) value count probability no 5 0.357143 yes 9 0.642857 entropy target = 0.9402859586706309 Mencari entropy setiap fitur : def findGain(column): entropyOutlook, groupOutlooks, rawOutlooks = findEntropy(column) table(groupOutlooks) gain = entropyTarget-sum(len(data)/len(df)*sum(-x/len(data)*log(x/len(data),2) for x in data.groupby('play').size()) for key,data in rawOutlooks) print( gain of ,column, is ,gain) return gain gains = [[x,findGain(x)] for x in ['outlook','temperature','humidity','windy']] value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391 value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647 value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136 value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927 Data dari setiap kolom table(DataFrame(gains, columns=[ Feature , Gain Score ]).sort_values( Gain Score )[::-1]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226","title":"TUGAS PENAMBANGAN DATA"},{"location":"#tugas-penambangan-data","text":"Nama : PRITA DYAH ANINDHITA NPM : 180411100125","title":"TUGAS PENAMBANGAN DATA"},{"location":"#tugas-1-menganalisa-data-statistika","text":"Penambangan data adalah bagaimana mendapatkan informasi yang berharga untuk pijakan pengambilan keputusan atau tujuan tertentu. Dalama proses data mining melibatkan teknik statistik, matematika, kecerdasan buatan, machine learning untuk mengekstraksi dan mengidentifikasi informasi yang bermanfaat dan pengetahuan yang terkait dari berbagai database besar. Proses yang umumnya dilakukan oleh data mining antara lain: deskripsi, prediksi, estimasi, klasifikasi, clustering dan asosiasi. Secara rinci proses data mining dijelaskan sebagai berikut (Larose, 2005):","title":"TUGAS 1 : Menganalisa Data Statistika"},{"location":"#a-deskripsi","text":"Deskripsi bertujuan untuk mengidentifikasi pola yang muncul secara berulang pada suatu data dan mengubah pola tersebut menjadi aturan dan kriteria yang dapat mudah dimengerti oleh para ahli pada domain aplikasinya. Aturan yang dihasilkan harus mudah dimengerti agar dapat dengan efektif meningkatkan tingkat pengetahuan (knowledge) pada sistem. Tugas deskriptif merupakan tugas data mining yang sering dibutuhkan pada teknik postprocessing untuk melakukan validasi dan menjelaskan hasil dari proses data mining. Postprocessing merupakan proses yang digunakan untuk memastikan hanya hasil yang valid dan berguna yang dapat digunakan oleh pihak yang berkepentingan.","title":"a. Deskripsi"},{"location":"#b-prediksi","text":"Prediksi memiliki kemiripan dengan klasifikasi, akan tetapi data diklasifikasikan berdasarkan perilaku atau nilai yang diperkirakan pada masa yang akan datang. Contoh dari tugas prediksi misalnya untuk memprediksikan adanya pengurangan jumlah pelanggan dalam waktu dekat dan prediksi harga saham dalam tiga bulan yang akan datang.","title":"b. Prediksi"},{"location":"#c-estimasi","text":"Estimasi hampir sama dengan prediksi, kecuali variabel target estimasi lebih ke arah numerik dari pada ke arah kategori. Model dibangun menggunakan record lengkap yang menyediakan nilai dari variabel target sebagai nilai prediksi. Selanjutnya, pada peninjauan berikutnya estimasi nilai dari variabel target dibuat berdasarkan nilai variabel prediksi. Sebagai contoh, akan dilakukan estimasi tekanan darah sistolik pada pasien rumah sakit berdasarkan umur pasien, jenis kelamin, berat badan, dan level sodium darah. Hubungan antara tekanan darah sistolik dan nilai variabel prediksi dalam proses pembelajaran akan menghasilkan model estimasi.","title":"c. Estimasi"},{"location":"#d-klasifikasi","text":"Klasifikasi merupakan proses menemukan sebuah model atau fungsi yang mendeskripsikan dan membedakan data ke dalam kelas-kelas. Klasifikasi melibatkan proses pemeriksaan karakteristik dari objek dan memasukkan objek ke dalam salah satu kelas yang sudah didefinisikan sebelumnya.","title":"d. Klasifikasi"},{"location":"#e-clustering","text":"Clustering merupakan pengelompokan data tanpa berdasarkan kelas data tertentu ke dalam kelas objek yang sama. Sebuah kluster adalah kumpulan record yang memiliki kemiripan suatu dengan yang lainnya dan memiliki ketidakmiripan dengan record dalam kluster lain. Tujuannya adalah untuk menghasilkan pengelompokan objek yang mirip satu sama lain dalam kelompok-kelompok. Semakin besar kemiripan objek dalam suatu cluster dan semakin besar perbedaan tiap cluster maka kualitas analisis cluster semakin baik.","title":"e. Clustering"},{"location":"#f-asosiasi","text":"Tugas asosiasi dalam data mining adalah menemukan atribut yang muncul dalam suatu waktu. Dalam dunia bisnis lebih umum disebut analisis keranjang belanja (market basket analisys). Tugas asosiasi berusaha untuk mengungkap aturan untuk mengukur hubungan antara dua atau lebih atribut.","title":"f. Asosiasi"},{"location":"#data-penjualan-celana-jeans","text":"ukuran harga terjual stok_akhir 27 199646 80 125 28 217629 68 120 33 194895 73 126 27 243520 59 114 33 189647 76 91 28 231199 57 99 28 201023 58 119 32 237461 73 94 28 181524 51 101 27 209713 78 107 31 196850 61 101 29 235810 57 92 30 210073 70 99 28 230566 79 127 27 191428 54 104 33 196716 69 127 33 180778 80 121 27 241827 66 114 30 235338 80 124 27 246301 64 98 28 242698 51 110 30 227316 80 91 28 213416 63 93 32 248338 54 127 32 189835 60 98 27 229830 65 124 29 228902 54 100 32 188186 70 108 29 214059 78 97 30 212963 50 127 31 178144 70 101 32 181112 67 124 27 221751 71 93 29 242167 77 108 27 197905 54 116 30 197365 51 116 30 215260 77 92 30 234018 71 90 31 217349 55 93 28 236345 79 98 29 200676 50 112 29 243220 80 107 31 240486 64 93 29 228497 62 112 31 201558 75 122 28 187013 76 101 32 238585 79 121 29 248879 53 119 31 220055 52 110 28 179157 74 119 32 218099 61 118 33 202469 73 108 28 196962 63 108 30 204666 76 109 31 220382 67 123 30 243236 65 116 32 231079 80 101 30 224545 80 102 32 204638 50 100 28 204997 56 98 33 175450 59 109 31 208584 71 107 29 181341 50 115 27 177602 76 96 29 244126 51 124 27 175884 69 106 29 194168 70 125 29 209596 70 90 31 216842 70 98 32 232769 78 125 33 242237 80 124 29 221570 53 90 32 234874 63 96 27 240559 50 95 28 186485 71 114 33 186471 60 128 28 204356 69 111 33 202393 59 92 27 194641 65 113 32 249103 78 127 29 221927 66 105 27 231445 70 103 28 244795 66 120 33 224554 70 114 31 186151 51 96 32 199054 55 111 28 237222 51 114 30 176109 76 100 33 208126 77 96 29 213399 62 108 28 193254 78 124 33 247786 52 114 32 233411 76 126 27 199631 79 106 29 234684 62 110 32 245464 62 110 33 232024 71 108 29 200812 64 90 30 198037 78 103 32 221239 52 90 Pengolahan Data import pandas as pd df = pd.read_csv( data_penjualan1.csv ) df from IPython.display import HTML, display import tabulate table=[ [ method ]+[x for x in df.columns], [ describe() ]+[' pre '+str(df[col].describe())+' /pre ' for col in df.columns], [ count() ]+[df[col].count() for col in df.columns], [ mean() ]+[df[col].mean() for col in df.columns], [ std() ]+[ {:.2f} .format(df[col].std()) for col in df.columns], [ min() ]+[df[col].min() for col in df.columns], [ max() ]+[df[col].max() for col in df.columns], [ q1() ]+[df[col].quantile(0.25) for col in df.columns], [ q2() ]+[df[col].quantile(0.50) for col in df.columns], [ q3() ]+[df[col].quantile(0.75) for col in df.columns], [ skew() ]+[ {:.2f} .format(df[col].skew()) for col in df.columns], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Hasil pengolahan data : method ukuran harga terjual stok_akhir describe() count 100.000000 count 100.000000 count 100.000000 count 100.000000 mean 29.850000 mean 214562.770000 mean 66.160000 mean 108.410000 std 2.031942 std 21792.270555 std 9.909408 std 11.655055 min 27.000000 min 175450.000000 min 50.000000 min 90.000000 25% 28.000000 25% 197264.250000 25% 57.750000 25% 98.000000 50% 30.000000 50% 214659.500000 50% 67.000000 50% 108.000000 75% 32.000000 75% 234184.500000 75% 76.000000 75% 119.000000 max 33.000000 max 249103.000000 max 80.000000 max 128.000000 Name: ukuran, dtype: float64 Name: harga, dtype: float64 Name: terjual, dtype: float64 Name: stok_akhir, dtype: float64 count() 100 100 100 100 mean() 29.85 214562.77 66.16 108.41 std() 2.03 21792.27 9.91 11.66 min() 27 175450 50 90 max() 33 249103 80 128 q1() 28 197264.25 57.75 98 q2() 30 214659.5 67 108 q3() 32 234184.5 76 119 skew() 0.14 -0.1 -0.19 0.07","title":"Data Penjualan Celana Jeans"},{"location":"#tugas-2-mengukur-jarak-data","text":"Dalam data, terdapat macam-macam atribut. Atribut adalah data yang mewakili karakteristik atau fitur dari objek data. Atribut bisa disebut juga dengan dimensi, fitur, dan variabel yang istilah itu sering digunakan literatur. Dalam penambangan data atau data miniing dan database biasa menggunakan istilah atribut atau fitur , dan dalam buku ini juga menggunakan istilah atribut atau fitur. Jenis atribut ditentukan oleh nilai-nilai pada atribut tersebut yang mungkin nominal, biner,atau ordinal, atau numerik. Mengukur Jarak Data Tipe Numerik : Minkowski Distance Manhattan Distance Euclidean Distance Average Distance Weighted Euclidean Distance Chord Distance Mahalanobis Distance Cosine Measure Pearson Measure Tipe Binary Tipe Categorical: Overlay metric Value Difference Metric Minimum Risk Metric Tipe Ordinal","title":"TUGAS 2 : Mengukur Jarak Data"},{"location":"#data-bupa-liver-disorder","text":"Title : BUPA liver disorders Source information : Creators : BUPA Medical Research Ltd. Donor : Richard S. Forsyth Address : 8 Grosvenor Avenue Mapperley Park Nottingham NG3 5DX 0602-621676 Date : 5/15/1990 import pandas as pd df = pd.read_csv( bupa_liver_disorder.csv ,nrows=4) df mcv alkphos spgt sgot gammagt drinks selector 0 85 92 45 27 31 0 1 1 85 64 59 32 23 0 2 2 86 54 33 16 54 0 2 3 91 78 34 24 36 0 2 binary=[6] num=[0,1,2,3,4,5] from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[0]+[0], [ v1-v3 ]+[0]+[0]+[0], [ v2-v3 ]+[0]+[0]+[0], [ v3-v4 ]+[0]+[0]+[0], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 0 0 v1-v3 0 0 0 v2-v3 0 0 0 v3-v4 0 0 0 def chordDist(v1,v2,jnis): jmlh=0 normv1=0 normv2=0 for x in range (len(jnis)): normv1=normv1+(int(df.values.tolist()[v1][jnis[x]])**2) normv2=normv2+(int(df.values.tolist()[v2][jnis[x]])**2) jmlh=jmlh+(int(df.values.tolist()[v1][jnis[x]])*int(df.values.tolist()[v2][jnis[x]])) return ((2-(2*jmlh/(normv1*normv2)))**0.5) from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[chordDist(0,1,num)]+[0], [ v1-v3 ]+[0]+[chordDist(0,2,num)]+[0], [ v2-v3 ]+[0]+[chordDist(1,2,num)]+[0], [ v3-v4 ]+[0]+[chordDist(2,3,num)]+[0], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 1.41421356237 0 v1-v3 0 1.41421356237 0 v2-v3 0 1.41421356237 0 v3-v4 0 1.41421356237 0 BINARY def binaryDist(v1,v2,jnis): q=0 r=0 s=0 t=0 for x in range (len(jnis)): if (int(df.values.tolist()[v1][jnis[x]]))==1 and (int(df.values.tolist()[v2][jnis[x]]))==1: q=q+1 elif (int(df.values.tolist()[v1][jnis[x]]))==1 and (int(df.values.tolist()[v2][jnis[x]]))==2: r=r+1 elif (int(df.values.tolist()[v1][jnis[x]]))==2 and (int(df.values.tolist()[v2][jnis[x]]))==1: s=s+1 else: t=t+1 return ((r+s)/(q+r+s+t)) from IPython.display import HTML, display import tabulate table=[ [ Data ]+[ Jarak ]+[ Numeric ]+[ Binary ], [ v1-v2 ]+[0]+[chordDist(0,1,num)]+[binaryDist(0,1,binary)], [ v1-v3 ]+[0]+[chordDist(0,2,num)]+[binaryDist(0,2,binary)], [ v2-v3 ]+[0]+[chordDist(1,2,num)]+[binaryDist(1,2,binary)], [ v3-v4 ]+[0]+[chordDist(2,3,num)]+[binaryDist(2,3,binary)], ] display(HTML(tabulate.tabulate(table, tablefmt='html'))) Data Jarak Numeric Binary v1-v2 0 1.41421356237 1 v1-v3 0 1.41421356237 1 v2-v3 0 1.41421356237 0 v3-v4 0 1.41421356237 0","title":"DATA BUPA LIVER DISORDER"},{"location":"#tugas-3-seleksi-fitur-information-gain","text":"Seleksi fitur merupakan salah satu fokus penelitian pada data mining untuk dataset yang memiliki atribut yang relatif banyak. Dengan menghilangkan beberapa atribut yang tidak relevan terhadap kelas label akan dapat meningkatkan kinerja algoritma klasifikasi. INFORMATION GAIN Information Gain adalah metode yang menggunakan teknik scoring untuk pembobotan sebuah fitur dengan menggunakan maksimal entropy from pandas import * from IPython.display import HTML, display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table(df): display(HTML(tabulate(df, tablefmt='html', headers='keys', showindex=False))) df = read_csv('newdata.csv', sep=';') table(df) outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no","title":"TUGAS 3 : SELEKSI FITUR INFORMATION GAIN"},{"location":"#mencari-entropy-target","text":"def findEntropy(column): rawGroups = df.groupby(column) targetGroups = [[key, len(data), len(data)/df[column].size] for key,data in rawGroups] targetGroups = DataFrame(targetGroups, columns=['value', 'count', 'probability']) return sum([-x*log(x,2) for x in targetGroups['probability']]), targetGroups, rawGroups entropyTarget, groupTargets, _ = findEntropy('play') table(groupTargets) print('entropy target =', entropyTarget) value count probability no 5 0.357143 yes 9 0.642857 entropy target = 0.9402859586706309 Mencari entropy setiap fitur : def findGain(column): entropyOutlook, groupOutlooks, rawOutlooks = findEntropy(column) table(groupOutlooks) gain = entropyTarget-sum(len(data)/len(df)*sum(-x/len(data)*log(x/len(data),2) for x in data.groupby('play').size()) for key,data in rawOutlooks) print( gain of ,column, is ,gain) return gain gains = [[x,findGain(x)] for x in ['outlook','temperature','humidity','windy']] value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391 value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647 value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136 value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927 Data dari setiap kolom table(DataFrame(gains, columns=[ Feature , Gain Score ]).sort_values( Gain Score )[::-1]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226","title":"Mencari Entropy Target"}]}